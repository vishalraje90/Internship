{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ab3bce-64cd-494f-a977-e3c0be172f9d",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars.\n",
    "2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6da4c70c-f5cd-4725-9d2d-f524bc741cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product to search: guitar\n",
      "Scraping page 1...\n",
      "Failed to retrieve search results.\n",
      "Scraping page 2...\n",
      "Failed to retrieve search results.\n",
      "Scraping page 3...\n",
      "Failed to retrieve search results.\n",
      "Data saved to amazon_products.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_amazon_search_results(search_query):\n",
    "    base_url = \"https://www.amazon.in\"\n",
    "    search_url = base_url + \"/s?k=\" + search_query.replace(\" \", \"+\")\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(\"Failed to retrieve search results.\")\n",
    "        return None\n",
    "\n",
    "def parse_search_results(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    products = []\n",
    "    results = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})\n",
    "    for result in results:\n",
    "        product = {}\n",
    "        try:\n",
    "            product[\"Brand Name\"] = result.find(\"span\", {\"class\": \"a-size-base-plus\"}).text.strip()\n",
    "        except:\n",
    "            product[\"Brand Name\"] = \"-\"\n",
    "        try:\n",
    "            product[\"Name of the Product\"] = result.find(\"span\", {\"class\": \"a-text-normal\"}).text.strip()\n",
    "        except:\n",
    "            product[\"Name of the Product\"] = \"-\"\n",
    "        try:\n",
    "            product[\"Price\"] = result.find(\"span\", {\"class\": \"a-offscreen\"}).text.strip()\n",
    "        except:\n",
    "            product[\"Price\"] = \"-\"\n",
    "        try:\n",
    "            product[\"Return/Exchange\"] = result.find(\"div\", {\"class\": \"a-row a-size-base a-color-secondary\"}).text.strip()\n",
    "        except:\n",
    "            product[\"Return/Exchange\"] = \"-\"\n",
    "        try:\n",
    "            product[\"Expected Delivery\"] = result.find(\"span\", {\"class\": \"a-text-bold\"}).text.strip()\n",
    "        except:\n",
    "            product[\"Expected Delivery\"] = \"-\"\n",
    "        try:\n",
    "            product[\"Availability\"] = result.find(\"span\", {\"class\": \"a-size-base\"}).text.strip()\n",
    "        except:\n",
    "            product[\"Availability\"] = \"-\"\n",
    "        try:\n",
    "            product[\"Product URL\"] = result.find(\"a\", {\"class\": \"a-link-normal\"}).get(\"href\")\n",
    "        except:\n",
    "            product[\"Product URL\"] = \"-\"\n",
    "        products.append(product)\n",
    "    return products\n",
    "\n",
    "def scrape_amazon_products(search_query, pages=3):\n",
    "    all_products = []\n",
    "    for page in range(1, pages+1):\n",
    "        print(f\"Scraping page {page}...\")\n",
    "        html = get_amazon_search_results(search_query + \"&page=\" + str(page))\n",
    "        if html:\n",
    "            products = parse_search_results(html)\n",
    "            all_products.extend(products)\n",
    "    return all_products\n",
    "\n",
    "def save_to_csv(products, filename):\n",
    "    df = pd.DataFrame(products)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_query = input(\"Enter the product to search: \")\n",
    "    products = scrape_amazon_products(search_query)\n",
    "    save_to_csv(products, \"amazon_products.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c960a6-b36c-4be9-bf5a-870f6b032339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/e0/7a/08f0ea19a0c835e88aad011083d9dda69a9dfa4585c3453b3bd842eb7bed/selenium-4.21.0-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.21.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\vishalraje\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/76/51/12d78ec8abcbda51d8f115d98ebd3ee3da9d9d9af00ac69d3097c5b8d51a/trio-0.25.1-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.25.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\vishalraje\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Collecting typing_extensions>=4.9.0 (from selenium)\n",
      "  Obtaining dependency information for typing_extensions>=4.9.0 from https://files.pythonhosted.org/packages/b6/53/84a859aaddfe7378a6e5820e864a2d75763e82b6fcbda1a00e92ec620bb7/typing_extensions-4.12.1-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for attrs>=23.2.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\vishalraje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\vishalraje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sniffio>=1.3.0 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\vishalraje\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for wsproto>=0.14 from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\vishalraje\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vishalraje\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for h11<1,>=0.9.0 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/9.5 MB 3.6 MB/s eta 0:00:03\n",
      "    --------------------------------------- 0.2/9.5 MB 3.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/9.5 MB 2.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/9.5 MB 2.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.8/9.5 MB 2.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.8/9.5 MB 2.3 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.9/9.5 MB 2.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/9.5 MB 2.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.2/9.5 MB 2.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.2/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.4/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.5/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.6/9.5 MB 2.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.7/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.8/9.5 MB 2.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.9/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.0/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.2/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.2/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.4/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.4/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.4/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.5/9.5 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.7/9.5 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.8/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.9/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.0/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.1/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.2/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.5 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.4/9.5 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.5/9.5 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.7/9.5 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.8/9.5 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.9/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.0/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.1/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.2/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.4/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.5/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.6/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.6/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.7/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.8/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.9/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.9/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.9/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.9/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.0/9.5 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.1/9.5 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.3/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.4/9.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.5/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.7/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.8/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.8/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.8/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.8/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.9/9.5 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.1/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.2/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.3/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.5/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.6/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.8/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.9/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.0/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.1/9.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.2/9.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.3/9.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.3/9.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.5/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.7/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.8/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.0/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.3/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.5/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.6/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.8/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.5/9.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
      "   ---------------------------------------- 0.0/467.7 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 112.6/467.7 kB 6.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 225.3/467.7 kB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 378.9/467.7 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  460.8/467.7 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 467.7/467.7 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.12.1-py3-none-any.whl (37 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 51.2/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 647.6 kB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 51.2/58.3 kB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 58.3/58.3 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: typing_extensions, sniffio, h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.1.0\n",
      "    Uninstalling attrs-22.1.0:\n",
      "      Successfully uninstalled attrs-22.1.0\n",
      "Successfully installed attrs-23.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.21.0 sniffio-1.3.1 trio-0.25.1 trio-websocket-0.11.1 typing_extensions-4.12.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81518b-d2cd-4284-8680-f6bea767aefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "595b3bde-94a6-479e-a7a3-5b39ec55e130",
   "metadata": {},
   "source": [
    "3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af7f4a94-8684-4ba7-ba9c-0f78f88b2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "def scrape_images(keyword, num_images):\n",
    "    try:\n",
    "        driver = webdriver.Chrome() \n",
    "        driver.get(\"https://images.google.com/\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        search_bar = driver.find_element(By.NAME,\"q\")\n",
    "        search_bar.clear()\n",
    "        search_bar.send_keys(keyword)\n",
    "        search_bar.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "        \n",
    "       \n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        \n",
    "        # Extract image URLs\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        img_tags = soup.find_all(\"img\", class_=\"rg_i\")\n",
    "        image_urls = [img['src'] for img in img_tags if img.get('src')]\n",
    "        image_urls = image_urls[:num_images]\n",
    "        \n",
    "        return image_urls\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping images for {keyword}: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "keywords = ['fruits', 'cars', 'Guitar', 'Cakes']\n",
    "num_images = 10\n",
    "    \n",
    "for keyword in keywords:\n",
    "     image_urls = scrape_images(keyword, num_images)\n",
    "     if image_urls:\n",
    "        download_images(keyword, image_urls, \"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88932d44-1073-4865-bb62-aee9a9adf5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b44a98b",
   "metadata": {},
   "source": [
    "4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "655d0d09-2034-4fdc-aa38-8f6c98ceb3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter smartphone name to search on Flipkart:  moto\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No smartphones found for the given search query.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "search_query = input(\"Enter smartphone name to search on Flipkart: \")\n",
    "smartphones = scrape_flipkart_smartphones(search_query) \n",
    "if smartphones:\n",
    "  df = pd.DataFrame(smartphones)\n",
    "  df.to_csv(f\"{search_query}_flipkart_smartphones.csv\", index=False)\n",
    "  print(\"Scraping completed. Results saved to CSV file.\")\n",
    "else:\n",
    "  print(\"No smartphones found for the given search query.\")\n",
    "\n",
    "def scrape_flipkart_smartphones(search_query):\n",
    "    url = f\"https://www.flipkart.com/search?q={search_query}%20&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(response)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    smartphones = []\n",
    "\n",
    "    for product in soup.find_all(\"div\", class_=\"_1AtVbE\"):\n",
    "        brand_name = product.find(\"div\", class_=\"_4rR01T\").text if product.find(\"div\", class_=\"_4rR01T\") else \"-\"\n",
    "        smartphone_name = product.find(\"a\", class_=\"IRpwTa\").text if product.find(\"a\", class_=\"IRpwTa\") else \"-\"\n",
    "        color = product.find(\"a\", class_=\"IRpwTa\").get(\"title\").split(')')[0].split('(')[-1] if product.find(\"a\", class_=\"IRpwTa\") else \"-\"\n",
    "        specifications = product.find_all(\"li\", class_=\"rgWa7D\")\n",
    "        ram = next((spec.find(\"li\") for spec in specifications if \"RAM\" in spec.text), \"-\")\n",
    "        rom = next((spec.find(\"li\") for spec in specifications if \"ROM\" in spec.text), \"-\")\n",
    "        primary_camera = next((spec.find(\"li\") for spec in specifications if \"MP Rear\" in spec.text), \"-\")\n",
    "        secondary_camera = next((spec.find(\"li\") for spec in specifications if \"MP Front\" in spec.text), \"-\")\n",
    "        display_size = next((spec.find(\"li\") for spec in specifications if \"cm (\" in spec.text), \"-\")\n",
    "        battery_capacity = next((spec.find(\"li\") for spec in specifications if \"mAh\" in spec.text), \"-\")\n",
    "        price = product.find(\"div\", class_=\"_30jeq3 _1_WHN1\").text if product.find(\"div\", class_=\"_30jeq3 _1_WHN1\") else \"-\"\n",
    "        product_url = \"https://www.flipkart.com\" + product.find(\"a\", class_=\"IRpwTa\")[\"href\"] if product.find(\"a\", class_=\"IRpwTa\") else \"-\"\n",
    "\n",
    "        smartphone = {\n",
    "            \"Brand Name\": brand_name,\n",
    "            \"Smartphone Name\": smartphone_name,\n",
    "            \"Colour\": color,\n",
    "            \"RAM\": ram.text if ram != \"-\" else \"-\",\n",
    "            \"Storage(ROM)\": rom.text if rom != \"-\" else \"-\",\n",
    "            \"Primary Camera\": primary_camera.text if primary_camera != \"-\" else \"-\",\n",
    "            \"Secondary Camera\": secondary_camera.text if secondary_camera != \"-\" else \"-\",\n",
    "            \"Display Size\": display_size.text if display_size != \"-\" else \"-\",\n",
    "            \"Battery Capacity\": battery_capacity.text if battery_capacity != \"-\" else \"-\",\n",
    "            \"Price\": price,\n",
    "            \"Product URL\": product_url\n",
    "        }\n",
    "        smartphones.append(smartphone)\n",
    "    \n",
    "    return smartphones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f526f-1d81-4a56-91ef-6a6374622a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f85a5d8-3859-4d80-a8a6-b2e95591c386",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "316b9a3c-1be1-4ed2-81d8-193efa92d432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter City Name : sangli\n",
      "URL Extracted:  https://www.google.co.in/maps/place/Sangli,+Maharashtra/@19.1004672,72.8891392,14z/data=!4m6!3m5!1s0x3bc10c8187f060eb:0x37911f53cdc1ddb3!8m2!3d16.8523973!4d74.5814773!16zL20vMDJucG1k?entry=ttu\n",
      "Latitude = 19.1004672, Longitude = 72.8891392\n"
     ]
    }
   ],
   "source": [
    "\n",
    "   \n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os   \n",
    "    \n",
    "driver.get(\"https://www.google.co.in/maps\")\n",
    "time.sleep(3)\n",
    "\n",
    "city = input('Enter City Name : ')                                         \n",
    "search = driver.find_element(By.ID,\"searchboxinput\")                       \n",
    "search.clear()                                                             \n",
    "time.sleep(2)\n",
    "search.send_keys(city)                                                     \n",
    "button = driver.find_element(By.ID,\"searchbox-searchbutton\")               \n",
    "button.click()                                                            \n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    url_string = driver.current_url\n",
    "    print(\"URL Extracted: \", url_string)\n",
    "    lat_lng = re.findall(r'@(.*)data',url_string)\n",
    "    if len(lat_lng):\n",
    "        lat_lng_list = lat_lng[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            lat = lat_lng_list[0]\n",
    "            lng = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(lat, lng))\n",
    "\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81762f-e46a-4240-a732-703d49ffa981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71ffb6-f70d-4f7e-a331-1e2d193f45be",
   "metadata": {},
   "source": [
    "6. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edf299bb-5fb2-4d39-b3ca-d1c9002c35c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "JavascriptException",
     "evalue": "Message: javascript error: {\"status\":32,\"value\":\"An invalid or illegal selector was specified\"}\n  (Session info: chrome=125.0.6422.141)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6C0A31F52+60322]\n\t(No symbol) [0x00007FF6C09ACEC9]\n\t(No symbol) [0x00007FF6C0867EBA]\n\t(No symbol) [0x00007FF6C086DCEE]\n\t(No symbol) [0x00007FF6C0870641]\n\t(No symbol) [0x00007FF6C08706E0]\n\t(No symbol) [0x00007FF6C08B733B]\n\t(No symbol) [0x00007FF6C08B773C]\n\t(No symbol) [0x00007FF6C08AAEEC]\n\t(No symbol) [0x00007FF6C08DC25F]\n\t(No symbol) [0x00007FF6C08AADB6]\n\t(No symbol) [0x00007FF6C08DC430]\n\t(No symbol) [0x00007FF6C08FBC80]\n\t(No symbol) [0x00007FF6C08DBFC3]\n\t(No symbol) [0x00007FF6C08A9617]\n\t(No symbol) [0x00007FF6C08AA211]\n\tGetHandleVerifier [0x00007FF6C0D494AD+3301629]\n\tGetHandleVerifier [0x00007FF6C0D936D3+3605283]\n\tGetHandleVerifier [0x00007FF6C0D89450+3563680]\n\tGetHandleVerifier [0x00007FF6C0AE4326+790390]\n\t(No symbol) [0x00007FF6C09B750F]\n\t(No symbol) [0x00007FF6C09B3404]\n\t(No symbol) [0x00007FF6C09B3592]\n\t(No symbol) [0x00007FF6C09A2F9F]\n\tBaseThreadInitThunk [0x00007FFE7ABA7614+20]\n\tRtlUserThreadStart [0x00007FFE7BD426A1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJavascriptException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m laptop_details \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m laptop \u001b[38;5;129;01min\u001b[39;00m laptop_elements:\n\u001b[1;32m---> 23\u001b[0m   name \u001b[38;5;241m=\u001b[39m laptop\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cat_for_grid lineheight15\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     24\u001b[0m   price \u001b[38;5;241m=\u001b[39m laptop\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearchPrice\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     25\u001b[0m   specifications \u001b[38;5;241m=\u001b[39m laptop\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearchSpec\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:417\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    414\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    415\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(Command\u001b[38;5;241m.\u001b[39mFIND_CHILD_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mJavascriptException\u001b[0m: Message: javascript error: {\"status\":32,\"value\":\"An invalid or illegal selector was specified\"}\n  (Session info: chrome=125.0.6422.141)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6C0A31F52+60322]\n\t(No symbol) [0x00007FF6C09ACEC9]\n\t(No symbol) [0x00007FF6C0867EBA]\n\t(No symbol) [0x00007FF6C086DCEE]\n\t(No symbol) [0x00007FF6C0870641]\n\t(No symbol) [0x00007FF6C08706E0]\n\t(No symbol) [0x00007FF6C08B733B]\n\t(No symbol) [0x00007FF6C08B773C]\n\t(No symbol) [0x00007FF6C08AAEEC]\n\t(No symbol) [0x00007FF6C08DC25F]\n\t(No symbol) [0x00007FF6C08AADB6]\n\t(No symbol) [0x00007FF6C08DC430]\n\t(No symbol) [0x00007FF6C08FBC80]\n\t(No symbol) [0x00007FF6C08DBFC3]\n\t(No symbol) [0x00007FF6C08A9617]\n\t(No symbol) [0x00007FF6C08AA211]\n\tGetHandleVerifier [0x00007FF6C0D494AD+3301629]\n\tGetHandleVerifier [0x00007FF6C0D936D3+3605283]\n\tGetHandleVerifier [0x00007FF6C0D89450+3563680]\n\tGetHandleVerifier [0x00007FF6C0AE4326+790390]\n\t(No symbol) [0x00007FF6C09B750F]\n\t(No symbol) [0x00007FF6C09B3404]\n\t(No symbol) [0x00007FF6C09B3592]\n\t(No symbol) [0x00007FF6C09A2F9F]\n\tBaseThreadInitThunk [0x00007FFE7ABA7614+20]\n\tRtlUserThreadStart [0x00007FFE7BD426A1+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "driver.get('https://www.digit.in/')\n",
    "\n",
    "\n",
    "search_bar = driver.find_element(By.CLASS_NAME,'re-ajax-search')\n",
    "search_bar.send_keys('gaming laptops')\n",
    "search_bar.submit()\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "laptop_elements = driver.find_elements(By.CLASS_NAME,'wcapf-before-products')\n",
    "laptop_details = []\n",
    "\n",
    "for laptop in laptop_elements:\n",
    "  name = laptop.find_element(By.CLASS_NAME,' cat_for_grid lineheight15').text\n",
    "  price = laptop.find_element(By.CLASS_NAME,'searchPrice').text\n",
    "  specifications = laptop.find_element(By.CLASS_NAME,'searchSpec').text\n",
    "  \n",
    "  laptop_details.append({\n",
    "  'Name': name,\n",
    "  'Price': price,\n",
    "  'Specifications': specifications\n",
    "  })\n",
    "\n",
    "\n",
    "for laptop in laptop_details:\n",
    "  print(laptop)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77389589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
